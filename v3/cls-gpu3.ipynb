{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_project_path: ../data/proteinnet/\n"
     ]
    }
   ],
   "source": [
    "local_path = '../'\n",
    "\n",
    "\"\"\"## Prepare fastai\"\"\"\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.metrics import *\n",
    "from fastai.callbacks.tensorboard import LearnerTensorboardWriter\n",
    "from fastai.callbacks.misc import StopAfterNBatches\n",
    "from fastai.callbacks.oversampling import OverSamplingCallback\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "np.random.seed(0)\n",
    "\n",
    "\"\"\"## Prepare Dataset\"\"\"\n",
    "local_project_path = local_path + 'data/proteinnet/'\n",
    "if not os.path.exists(local_project_path):\n",
    "    os.makedirs(local_project_path)\n",
    "print('local_project_path:', local_project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Tokenization\"\"\"\n",
    "class dna_tokenizer(BaseTokenizer):\n",
    "    def tokenizer(self, t):\n",
    "#         return list(t)\n",
    "        res = []\n",
    "        tokens = t.split(' ')\n",
    "        before_seq = tokens[:-2]\n",
    "        seq = tokens[-2]\n",
    "        eos = tokens[-1]\n",
    "        \n",
    "        res = before_seq\n",
    "        res += list(seq) # sequence string to list\n",
    "        res.append(eos)\n",
    "        \n",
    "        return res\n",
    "tokenizer = Tokenizer(tok_func=dna_tokenizer, pre_rules=[], post_rules=[], special_cases=[])\n",
    "processor = [TokenizeProcessor(tokenizer=tokenizer, include_bos= True, include_eos=True), NumericalizeProcessor(max_vocab=30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_cls Training set size 99908\n",
      "data_cls Validation set size 11101\n"
     ]
    }
   ],
   "source": [
    "# batch size\n",
    "bs = 128\n",
    "data_lm = TextLMDataBunch.from_csv(local_project_path, 'test.csv',\n",
    "                                   text_cols ='seq', valid_pct= 0.1, tokenizer=tokenizer,\n",
    "                                   include_bos= True, include_eos=True, bs=bs)\n",
    "print('data_cls Training set size', len(data_lm.train_ds))\n",
    "print('data_cls Validation set size', len(data_lm.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_full = pickle.load(open('train_df', 'rb'))\n",
    "train_df = train_df_full[['seq','GO']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_GO0005525'] = train_df.apply(lambda row: 'T' if 'GO:0005525' in row.GO else 'F', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>GO</th>\n",
       "      <th>is_GO0005525</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accession</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A060X6Z0</th>\n",
       "      <td>MPISSSSSSSTKSMRRAASELERSDSVTSPRFIGRRQSLIEDARKE...</td>\n",
       "      <td>GO:0070852 GO:0043204 GO:0004511</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A068FIK2</th>\n",
       "      <td>MEVGGGSEECCVKVAVHVRPLIGDEKVQGCKDCVTVIPGKPQVQIG...</td>\n",
       "      <td>GO:0055028 GO:0005737</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075F932</th>\n",
       "      <td>MVSESHHEALAAPPATTVAAAPPSNVTEPASPGGGGGKEDAFSKLK...</td>\n",
       "      <td>GO:0048609 GO:0046883</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A078CGE6</th>\n",
       "      <td>MARQMTSSQFHKSKTLDNKYMLGDEIGKGAYGRVYIGLDLENGDFV...</td>\n",
       "      <td>GO:0005730 GO:0004674 GO:0046777 GO:0051302</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A086F3E3</th>\n",
       "      <td>MTKGRLEAFSDGVLAIIITIMVLELKVPEGSSWASLQPILPRFLAY...</td>\n",
       "      <td>GO:0022841 GO:0071805</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          seq  \\\n",
       "accession                                                       \n",
       "A0A060X6Z0  MPISSSSSSSTKSMRRAASELERSDSVTSPRFIGRRQSLIEDARKE...   \n",
       "A0A068FIK2  MEVGGGSEECCVKVAVHVRPLIGDEKVQGCKDCVTVIPGKPQVQIG...   \n",
       "A0A075F932  MVSESHHEALAAPPATTVAAAPPSNVTEPASPGGGGGKEDAFSKLK...   \n",
       "A0A078CGE6  MARQMTSSQFHKSKTLDNKYMLGDEIGKGAYGRVYIGLDLENGDFV...   \n",
       "A0A086F3E3  MTKGRLEAFSDGVLAIIITIMVLELKVPEGSSWASLQPILPRFLAY...   \n",
       "\n",
       "                                                     GO is_GO0005525  \n",
       "accession                                                             \n",
       "A0A060X6Z0             GO:0070852 GO:0043204 GO:0004511            F  \n",
       "A0A068FIK2                        GO:0055028 GO:0005737            F  \n",
       "A0A075F932                        GO:0048609 GO:0046883            F  \n",
       "A0A078CGE6  GO:0005730 GO:0004674 GO:0046777 GO:0051302            F  \n",
       "A0A086F3E3                        GO:0022841 GO:0071805            F  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df['is_GO0005525'] == 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66550"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df['is_GO0005525'] == 'F').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = 512\n",
    "# data_cls = (TextList.from_df(train_df, path = local_project_path, cols='seq', vocab=data_lm.vocab, processor=processor)\n",
    "#                     .split_by_rand_pct(0.10)\n",
    "#                    .label_from_df(cols='is_GO0005525', label_delim=' ')\n",
    "#                    .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "data_cls = (TextList.from_csv('./', 'train_df.csv', cols='seq', vocab=data_lm.vocab, processor=processor)\n",
    "                    .split_by_rand_pct(0.10)\n",
    "                   .label_from_df(cols='is_GO0005525', label_delim=' ')\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_cls.train_ds))\n",
    "print(len(data_cls.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls.train_ds.x[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls.train_ds.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # batch size\n",
    "# bs = 256\n",
    "# data_cls = TextClasDataBunch.from_csv(local_project_path, 'uniprot_sprot_exp_go_F.csv',\n",
    "#                                    text_cols ='seq', valid_pct= 0.1, tokenizer=tokenizer,\n",
    "#                                    include_bos= True, include_eos=True, classes='labels', bs=bs)\n",
    "# print('data_cls Training set size', len(data_lm.train_ds))\n",
    "# print('data_cls Validation set size', len(data_lm.valid_ds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_02 = partial(accuracy_thresh, thresh=0.5)\n",
    "# f_score = partial(fbeta, thresh=0.5, beta=1)\n",
    "from sklearn.metrics import f1_score\n",
    "@np_func\n",
    "def f1(inp,targ): return f1_score(targ, np.argmax(inp, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls = text_classifier_learner(data_cls, AWD_LSTM, drop_mult=0.5, pretrained=False, \n",
    "                                    metrics=[accuracy, f1],\n",
    "                                    callback_fns=[\n",
    "                                        OverSamplingCallback\n",
    "                                    ]\n",
    "                                   ).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "learn_cls.path = Path(local_project_path)\n",
    "learn_cls.load_encoder('lm-gpu3-sp-40M-v2-enc');\n",
    "learn_cls.freeze();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_cls.data.batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tensorboard_callback(learn):\n",
    "    now = datetime.datetime.now().astimezone(timezone('US/Eastern'))\n",
    "    time_for_different_run = f'{now.year}-{now.month}-{now.day}-{now.hour}-{now.minute}-{now.second}'\n",
    "\n",
    "    proj_id = 'cafa' + time_for_different_run\n",
    "    tboard_path = Path('log/' + proj_id)\n",
    "    remove_tensorboard_callback(learn)\n",
    "    learn.callback_fns.append(partial(LearnerTensorboardWriter, base_dir=tboard_path, name='CafaLearner'))\n",
    "\n",
    "def remove_tensorboard_callback(learn):\n",
    "    if len(learn.callback_fns) > 1: # not the best way to check this !!\n",
    "        learn.callback_fns.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_tensorboard_callback(learn_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_tensorboard_callback(learn_cls)\n",
    "# learn_cls.lr_find()\n",
    "# add_tensorboard_callback(learn_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_cls.recorder.plot(skip_start=5, skip_end=10, suggestion = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_cls.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_cls.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_cls.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-2\n",
    "learn_cls.fit_one_cycle(1, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.validate(metrics=[partial(accuracy_thresh, thresh=0.5), partial(fbeta, thresh=0.5, beta = 1), top_k_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = learn_cls.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,targs = learn_c.get_preds(ordered=True)\n",
    "accuracy(preds,targs),f1(preds,targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses,idxs = interp.top_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cls.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(15,15), dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(losses > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cls.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_project_path: ./data/cafa3/\n"
     ]
    }
   ],
   "source": [
    "local_path = './'\n",
    "\n",
    "\"\"\"## Prepare fastai\"\"\"\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.metrics import *\n",
    "from fastai.callbacks.tensorboard import LearnerTensorboardWriter\n",
    "from fastai.callbacks.misc import StopAfterNBatches\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "np.random.seed(0)\n",
    "\"\"\"## Prepare Dataset\"\"\"\n",
    "local_project_path = local_path + 'data/cafa3/'\n",
    "if not os.path.exists(local_project_path):\n",
    "    os.makedirs(local_project_path)\n",
    "print('local_project_path:', local_project_path)\n",
    "\n",
    "\"\"\"## Create Language Model\"\"\"\n",
    "class dna_tokenizer(BaseTokenizer):\n",
    "    def tokenizer(self, t):\n",
    "        res = []\n",
    "        tokens = t.split(' ')\n",
    "        if len(tokens) == 3:\n",
    "            bos = tokens[0]\n",
    "            text = tokens[1]\n",
    "            eos = tokens[2]\n",
    "            res = list(text)\n",
    "            res.insert(0, bos)\n",
    "            res.append(eos)\n",
    "        else:\n",
    "            res = list(tokens)\n",
    "        return res\n",
    "tokenizer = Tokenizer(tok_func=dna_tokenizer, pre_rules=[], post_rules=[], special_cases=[])\n",
    "processor = [TokenizeProcessor(tokenizer=tokenizer, include_bos= True, include_eos=True), NumericalizeProcessor(max_vocab=30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "bs = 8\n",
    "data_lm = TextLMDataBunch.from_csv('bp_deepred/', 'combined.csv',\n",
    "                                   text_cols ='seq', valid_pct= 0.1, tokenizer=tokenizer,\n",
    "                                   include_bos= True, include_eos=True, bs=bs)\n",
    "print('data_cls Training set size', len(data_lm.train_ds))\n",
    "print('data_cls Validation set size', len(data_lm.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls = (TextList.from_csv(local_project_path, 'uniprot_sprot_exp_go_all.csv', cols='seq', vocab=data_lm.vocab, processor=processor)\n",
    "                    .split_by_rand_pct(0.10)\n",
    "                   .label_from_df(cols='labels', label_delim=' ')\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_cls.train_ds))\n",
    "print(len(data_cls.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls.train_ds.y[10400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # batch size\n",
    "# bs = 256\n",
    "# data_cls = TextClasDataBunch.from_csv(local_project_path, 'uniprot_sprot_exp_go_F.csv',\n",
    "#                                    text_cols ='seq', valid_pct= 0.1, tokenizer=tokenizer,\n",
    "#                                    include_bos= True, include_eos=True, classes='labels', bs=bs)\n",
    "# print('data_cls Training set size', len(data_lm.train_ds))\n",
    "# print('data_cls Validation set size', len(data_lm.valid_ds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_02 = partial(accuracy_thresh, thresh=0.5)\n",
    "f_score = partial(fbeta, thresh=0.5, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls = text_classifier_learner(data_cls, AWD_LSTM, drop_mult=0.05, pretrained=False, metrics =[acc_02, f_score]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.metrics =[acc_02, f_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.load_encoder('../../../bp_deepred/models/lm2-v2-21_enc');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.data.batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tensorboard_callback(learn_lm):\n",
    "    now = datetime.datetime.now().astimezone(timezone('US/Eastern'))\n",
    "    time_for_different_run = f'{now.year}-{now.month}-{now.day}-{now.hour}-{now.minute}-{now.second}'\n",
    "\n",
    "    proj_id = 'cafa' + time_for_different_run\n",
    "    tboard_path = Path('log/' + proj_id)\n",
    "    remove_tensorboard_callback(learn_lm)\n",
    "    learn_lm.callback_fns.append(partial(LearnerTensorboardWriter, base_dir=tboard_path, name='CafaLearner'))\n",
    "\n",
    "def remove_tensorboard_callback(learn_lm):\n",
    "    if len(learn_lm.callback_fns) > 1: # not the best way to check this !!\n",
    "        learn_lm.callback_fns.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tensorboard_callback(learn_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_tensorboard_callback(learn_cls)\n",
    "learn_cls.lr_find()\n",
    "add_tensorboard_callback(learn_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.recorder.plot(skip_start=20, skip_end=20, suggestion = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(1, slice(1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.validate(metrics=[partial(accuracy_thresh, thresh=0.5), partial(fbeta, thresh=0.5, beta = 1), top_k_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = learn_cls.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses,idxs = interp.top_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cls.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(15,15), dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(losses > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cls.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
